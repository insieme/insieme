\chapter{The Infrastructure} \label{cap:infrastructure}

\section{The Insieme Wiki}
\section{The Source Code Repository}
\input{infrastructure/03_libraries}
\section{The Build Script} \label{sec:Infrastructure.Build}

\section{The Integration Tests [Simone]}

Integration tests are used to test the Insieme compiler as a single entity,
checking that each compiler phase is working properly and correctly
interoperates with the others . The underlying idea is to
use real C/C++ codes, convert them into semantically correct IR and through the
backends produce C code which when executed produces the same output as the
original input code. At each step we verify that the intermediate results are
consistent with reference files which have been generated in the previous {\em
correct} run of the test. 

[when the master student assigned for this task will deliver his thesis, it can
be integrated here]

\subsection{Folder Organization}
Test cases are organized in a hierarchal directory structure. The leaf
directories contains the actual test cases whereas higher order directory are
used as logic containers with the goal to group test cases belonging to the same
category, e.g. the non-leaf {\tt ocl} directory contains OpenCL test cases. The
location of the integration test cases within the Insieme compiler project is in
the \file{test} folder. 

The integration test script recursively scans directories collecting all test
cases which are the leaves of the directory structure. However this behaviour
can be overloaded by adding a file called \file{test.cfg} into any
non-leaf directory. When this file is present the test script avoids to scan all
the sub folders from the current location, it instead reads the file content and
recurs only on the folder names listed in the \file{test.cfg} file.
The structure of the \file{test.cfg} must be a new-line separated list of
directory names which are direct sub folders of the current directory. See
\file{test/test.cfg} for an example. A line within the \file{test.cfg} file can
be commented by using the {\tt \#} symbol. 

\subsection{Test case Organization and Configuration (leaf directories)}
As stated, each leaf folder contains a test case. There are several ways for
declaring a new test case varying from basic to more advanced configurations. In
advanced configurations files are included within the test case folder which
will be interpret by the test script. 

The minimum test case consists of a single file ({\tt .c} or {\tt .cpp}) having
exactly the same name of the enclosing test case folder. An example is the
\file{test/hello\_world} test case example. The directory contains a single
file, i.e. \file{hello\_world.c}.

The default behaviour of the test script can be overloaded by means of files
whose semantics is described hereafter. Note that the name must be the same as
described here (case sensitive).

\begin{description}

	\item[\file{inputs.data}:]
		However, sometimes a test case is composed by multiple translation units. In
		order to allow such codes the user can define a file called \file{inputs.data}
		within the test case folder. This file must contain a space separated list of
		input source files ({\tt .c} or {\tt .cpp}). When this file is present, the
		integration test script will not look for a file having the same name of the
		current folder but instead it will only consider the ones provided in this
		file. This file is also useful when the test case is using source codes
		which are already store in a different test case folder. For example every
		OpenMP test case is both tested for the sequential version and the
		parallel one as two distinct test cases. Source codes are shared, see
		\file{test/omp/jacobi} as an example. 

	\item[\file{insieme.flags}:] For a test case we may want to enable a specific
		set of flags of the insieme compiler or provide a pre-processor directive
		required during the compilation process. The file \file{insieme.flags}
		allows the programmer to provide custom settings in a per-test case way. 

	\item[\file{ref-gcc.flags}:] Sometimes beside providing specific flags to the
		Insieme compiler, we need to customize the way the original code is
		compiled. The file \file{ref-gcc.flags} allows the programmer to specify
		such flags. It is worth notice that the flags specified here are only used
		to compile the original code and not the code which is generated as output
		of the Insieme source-to-source process. 

	\item[\file{test-gcc.flags}:] Compiler configurations which are applied
		to code generated by the Insieme backend are instead provided in the
		\file{test-gcc.fags} file. An example of test case using all of these
		features is the \file{test/ocl/nbody} test case. 

	\item[\file{prog.input}:] By default the input program is compiled into an
		executable and then executed. However, in some cases the executable needs
		input arguments to be passed or it has to be executed through a
		third-party script (e.g. {\tt mpirun}). When the file \file{prog.input} is
		present, the command line string to execute the command is read from that
		file. Within the file the programmer can use {\tt \{EXEC\}} to refer to
		the executable (since different executable are often generated depending
		on the selected backend). Additionally the {\tt \{PATH\}} placeholder can
		be use to refer to the current path. An example of the content of this
		file is the following: 
		\begin{verbatim} 
		mpirun -n 2 {PATH}/{EXEC} arguments
		\end{verbatim} 

	\item[\file{output.match}:] Sometimes we do not want to compare the entire
		application output since timer might be used and the output files may be
		not byte-to-byte identical. This would make the test fail even if the
		execution was successful. In order to avoid this we can extract a set of
		meaningful information from the generated output of the test case and
		perform the comparison only on that. This is done by the
		\file{output.match} file. Inside we can specify an instruction which will
		perform the extraction, the output will be saved on a temporary file which
		will be then used for the diff. An example of a matcher which extract the
		value of the verification step (performed by one of the test cases) can be
		defined as follows: 
		\begin{verbatim} 
		awk '/^Verification\s+=\s\w+$/{ print $3 }'
		\end{verbatim} 

\end{description}

\subsubsection{Passes}
The last file name which is interpreted by the integration test case is the
\file{passes} file. The integration test script defines several passes which can
be applied to a test case, default passes are the following:

\begin{description}

	\item[\texttt{gcc}:] Runs GCC on the test case source code, generate an executable and
		runs it.

	\item[\texttt{sema}:] Runs the Insieme compiler on the test case source code,
		generates the corresponding IR and perform the semantic checks.

	\item[\texttt{c\_seq}:] Runs the Insieme compiler on the test case source code,
		generates the corresponding IR, invokes the sequential backend
		(transforming IR code into C code), compiles and run the generated code.

	\item[\texttt{c\_run}:] Similar to the previous pass, but this time the output C
		code is produced using the runtime backend and executed in parallel. 

	\item[\texttt{ocl}:] Uses the OpenCL backend and runtime. 

\end{description}

We will show later how new passes can be easily defined to take into account new
scenarios (e.g. C++ integration tests, MPI integration tests). Clearly not all
passes can be used with every test case, e.g. it makes little sense to run a
sequential test case using the OpenCL backend and runtime system. The
\file{passes} file used in order to let the integration test script know which
{\em passes} should be used for a particular folder (and sub-folders).

The structure is again fairly easy, the file contains the list of passes, using their
names, which should be enabled. It is also possible to disable a specific pass
(probably enabled at a higher level) prepending the {\tt \char`\^} symbol to the pass
name. For example the string:
\begin{verbatim} 
gcc sema ^c_run
\end{verbatim} 
Enables the {\tt gcc} and the {\tt sema} pass and disable the {\tt c\_run}. When
the integration test will execute the test cases contained within this folder
only the first two configurations will be enabled the runtime backend will not
be tested (unless overwritten in one of the sub-folders).

Passes files can be place either in test case folders (leaf-directories) or in
higher levels. Specifications at the lower level always precedes the more
general configuration found on parent folders.  

\subsection{Running the Integration tests} 

After configured the environment with {\tt cmake} a \file{integration\_tests.py}
file will be available in the build folder. Launching the script can be done
with:

\begin{verbatim}
$> ./integration_tests.py 
\end{verbatim}

Since the majority of the passes tested by the integration test script requires
the Insieme compiler executable, make sure to run a {\tt make main} before
launching the integration tests.

This script is written in Python 3.x, therefore makes sure you have a version of
the Python interpreter which is at least 3.0.  The available options are
accessed through the {\tt --help} command line parameter, the most important
flags are herein explained:

\begin{description}

	\item [{\tt -w NUM}:] Used to specify the number of parallel executors to be
		used for running the test cases. The script runs test cases in parallel to
		reduce the time required for integration tests. Output of the script is
		kept ordered by printing the output of a specific test case only when all
		its parts has been executed. 

	\item [{\tt -c | --clean}:] Removes all the reference files which have been
		generated in the previous run. 

	\item[{\tt -m | --mock-run}:] Produce as output the list of commands which
		are generated by the integration script to test a particular test case.
		The generated commands always contain absolute paths, therefore they can
		be executed from any location of the current machine. 

	\item[{\tt -r NUM}:] Instead of running each executable only once, it runs it
		multiple times (exactly {\tt NUM}) and in the test case report prints
		information on the average execution time and the standard deviation. 

	\item[{\tt -b passes}:] Allows the programmer to specify the list of passes
		which should be used.  \\
		{\bf\tt NOTE:} Because of an implementation issue, the script will still
		prioritize the configuration given by the \file{passes} files over the one
		provided by the command line even though the contrary should be
		preferable.

\end{description}

The script by default load all the test scripts from the \file{test/} folder.
However the path to test cases can be provided via the command line to execute
only a subset of the tests. For example:

\begin{verbatim}
$> ./integration_tests.py test/omp/ test/ocl
\end{verbatim}

Executes all of the OpenMP and OpenCL test cases. Also wildcards are allowed,
for example we can execute all test cases which are direct sub-folders of the
\file{test} directory starting with the letter 'o' as follows:

\begin{verbatim}
$> ./integration_tests.py test/o*
\end{verbatim}

Or as said before, only execute a subset of the passes and run the tests in
parallel using 4 workers:

\begin{verbatim}
$> ./integration_tests.py -b gcc,sema -w 4
\end{verbatim}

\subsection{Adding a new Integration test case} 

Adding a new test is easy. 
\begin{itemize}
	\item First of all find the correct location where to place
		your test. C++ test cases must be placed under the \file{test/cpp} folder.
		OpenMP tests are inside the \file{test/omp} folder. 

	\item Secondly create a directory with the name of the test case, add the
		source files and any other configuration file required to implement your
		test. 

	\item It is important that before executing the test case you add the files
		to the source code repository using {\tt git add}. Since we don't want to
		store the reference files within the git repository, adding the test case
		at this point will simplify your life. 
	
	\item Use the integration test script, by providing the test case path as
		input, to check whether your test case is working as expected.

	\item If the test case is within a folder containing a \file{test.cfg} file,
		add the name of the test case (which is the same as the folder) to that
		file.

	\item Commit and push the changes. 

\end{itemize}


\subsection{Architecture Overview}

The integration test script is divided into two parts, the code and a
configuration file used to extend the behaviour and capabilities of the script.
The source code of the script itself is in \file{test/integration\_tests.py.in}
while the configuration file is \file{test/config.cfg.in}. Please notice that
these files contains wildcards which are replaced by the {\tt cmake} during the
configuration process and replaced accordingly to point to the build folder
(where the Insieme compiler executable and integration test suite will be
available). The file produced by the {\tt cmake} is then placed in the root
folder of the project. Be aware that any change to the file
\file{./integration\_tests.py} or \file{./test.cfg} in the root directory will
be overwritten every time the cmake is executed.  Any permanent change to the
test script should be applied to the files within the test folder. 

\subsubsection{The Script}

The test script is made up two principal components: the {\em runner} and the
{\rm reporter} which follow a producer/consumer scheme. The {\em runner} takes
care of executing commands while the main responsibility of the {\em reporter}
is to display the outcome of a particular test case. Since test cases can be
executed in parallel, many {\em runners} may coexists; however one and only one
{\em reporter} is instantiated at any time. This allows us to display results of
test cases in order without messing up the output of the console. Exchange of
data between the two entities is done using a global queue called {\tt
completed} to which producers enqueue content while the only consumer dequeues
it. 

The structure of the script follows a {\em command} design pattern. At the
beginning of the script we scan the input argument looking for folders provided
by the user he wants to be tested. After that we recursively visit the top
folders looking for leaf elements which are the single tests cases which needs
to be executed. Successively a descriptor for each test cases is generated, this
class is called \type{TestJob}. 

The constructor of the \type{TestJob} class examine the test case by looking at
the files within the folder and gather all required information necessary to
execute it (for example it also scan parent folders collecting the passes
defined to be executed, or not, for this test case). An array containing the
passes which are enabled for this test case is generated, \type{cur\_passes}.


{\tt\bf NOTE:} this algorithm needs some rethinking since as already stated, the
passes provided by input arguments should always overwrite the one provided
within the passes files in the filesystem. 


For each of the selected passes we then generate the commands which implement
that pass. Commands can be a compilation process {\tt Commands.COMPILE}, a diff
between two files {\tt Commands.DIFF}, a copy of a file from one location to
another {\tt Commands.COPY}, the extraction of a pattern from a file {\tt
Commands.EXT} and at last, the execution of a command {\tt Command.RUN}. For
each test case two streams of commands are generated. The first one contains the
{\em hard} commands, the second {\em finalization} command. The semantics is
that finalization commands (which usually require clearing temporary files, or
generation of reference files) are not executed if one or more of the {\em hard}
commands fails. Finalization commands are always executed after.

\subsubsection{The Configuration file}

The script is written in a way that new capabilities can be integrated using the
configuration file \file{test/test.cfg.in}. This file is automatically parsed by
the Python config parser module (available in the standard library). A keyword,
or variable is defined as follows:

\begin{srcCode}
NAME:	DEFINITION
\end{srcCode}

Whenever {\tt NAME} needs to be used within another definition, the {\tt
\%(NAME)s} expression must be used. 

The bottom of the file contains the list of defined passes. All passes must
start with the keyword {\tt pass}. The second component, a number, is utilized
to give an order to the phase (or priority) so that a specific pass always
precedes another one. For example since there is no point to generate IR code
from an input program which is not correct; the {\tt gcc} pass have the highest
priority; if it fails successive steps will not be executed. The last component
is the name of the pass which can be referred to in the {\tt passes} files
explained in the previous section. The three components are separated by dots. 

A pass is represented by the \type{Pass} object. It is composed by 4 main
components. 

\begin{description}

	\item[Pre-processing phase]: The first parameter of the \type{Pass}
		constructor is the command executed as preprocessing of the source code.
		In many cases this is the source-to-source compilation step executed by
		the Insieme compiler. The second argument of the constructor is also
		relative to this phase and it contains the {\em extension} of the file
		which is generated by this first step. 

	\item[Backend compiler phase]: With the third argument we enter the second
		phase, i.e. execution of the backend compiler. This phase uses the file
		generated in the previous step and as in a pipeline processes it. This is
		the step when machine code is actually generated. The forth argument is
		again connected to this phase and allows us to specify the name of the
		extension of the executable being generated as result of this step. 

	\item[Execution phase]: It is represented by the fifth and last argument and
		it is used to specify how the produced executable should be executed. This
		was added just to account for execution of MPI test cases but this has
		been then resolved using a different mechanism, therefore this argument is
		redundant, it can be removed (however it could be useful also for future
		extensions).

\end{description}

During the design there was no need to provide longer pipelines, however the
design of the \type{Pass} class can be easily generalized with a variable number
of steps. Invocations to compilers (both Insieme or GCC) are done by building a
sequence of flags to be used. This is done using the \type{Conf} class which has
the responsibility to put compilation flag together and produce a string which
can be invoked by the command line. Also a flag as its own wrapping class
\type{Flag} which provides utilities for handling flags referring to actual
files, e.g. {\tt -o file}.

\subsubsection{Defining a new Pass}

Definition of a new phase is also easy. Just define a new entry at the end of the
\file{test/test.cfg.in} file. Follow the pattern specified above, use {\tt
pass.ID.NAME}. Then provide information for the three steps making sure that
you choose a different pattern for the intermediate file (the script will not
perform any checks on this). 

A new phase is enabled by default since the \file{test/passes} file contains the
{\tt all} keyword which loads all available passes for each test cases. However
make sure to disable the test, i.e. {\tt \char`\^NAME}, for the sub-folders for
which you don't want the test case to be executed. Alternatively you can disable
it from the root folder and selectively enabled it again in a test case-specific
way. 

\section{Machines}
